{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77dd899",
   "metadata": {},
   "source": [
    "# Lab Three - Extending Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20179136",
   "metadata": {},
   "source": [
    "Use Sex, Age, country, and marital-status to predict education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db598af3",
   "metadata": {},
   "source": [
    "## Preperation and Overview\n",
    "### Business Case\n",
    "WIP\n",
    "### Pre-Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ebd2ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate values:  0\n",
      "Missing Values Present:  0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4177 non-null   object \n",
      " 1   Length          4177 non-null   float64\n",
      " 2   Diameter        4177 non-null   float64\n",
      " 3   Height          4177 non-null   float64\n",
      " 4   Whole-Weight    4177 non-null   float64\n",
      " 5   Shucked-Weight  4177 non-null   float64\n",
      " 6   Viscera-Weight  4177 non-null   float64\n",
      " 7   Shell-Weight    4177 non-null   float64\n",
      " 8   Rings           4177 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 293.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as mn\n",
    "\n",
    "initData = pd.read_csv('/home/tommy/Downloads/abalone.data')\n",
    "initData.groupby(['Rings']).size()\n",
    "duplicates = initData.duplicated().loc[initData.duplicated() == True].count()\n",
    "print(\"Number of duplicate values: \", duplicates)\n",
    "print(\"Missing Values Present: \", initData.isnull().values.sum())\n",
    "initData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4490cf5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rings\n",
      "1       1\n",
      "2       1\n",
      "3      15\n",
      "4      57\n",
      "5     115\n",
      "6     259\n",
      "7     391\n",
      "8     568\n",
      "9     689\n",
      "10    634\n",
      "11    487\n",
      "12    267\n",
      "13    203\n",
      "14    126\n",
      "15    103\n",
      "16     67\n",
      "17     58\n",
      "18     42\n",
      "19     32\n",
      "20     26\n",
      "21     14\n",
      "22      6\n",
      "23      9\n",
      "24      2\n",
      "25      1\n",
      "26      1\n",
      "27      2\n",
      "29      1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole-Weight</th>\n",
       "      <th>Shucked-Weight</th>\n",
       "      <th>Viscera-Weight</th>\n",
       "      <th>Shell-Weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole-Weight  Shucked-Weight  Viscera-Weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell-Weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(initData.groupby(['Rings']).size())\n",
    "initData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d39cff",
   "metadata": {},
   "source": [
    "Before I use the data, I first one hot encode the sex class. Under normal circumstances, this would yield a single binary attribute; however, there are three unique values for sex in the dataset: male, female, and infant, so instead three attributes will be needed. I'm also discretizing the the number of rings into three ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3dc5cd92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole-Weight</th>\n",
       "      <th>Shucked-Weight</th>\n",
       "      <th>Viscera-Weight</th>\n",
       "      <th>Shell-Weight</th>\n",
       "      <th>Female</th>\n",
       "      <th>Infant</th>\n",
       "      <th>Male</th>\n",
       "      <th>Ring-Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole-Weight  Shucked-Weight  Viscera-Weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell-Weight  Female  Infant  Male Ring-Range  \n",
       "0         0.150       0       0     1      11-30  \n",
       "1         0.070       0       0     1        1-8  \n",
       "2         0.210       1       0     0       9-10  \n",
       "3         0.155       0       0     1       9-10  \n",
       "4         0.055       0       1     0        1-8  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding Sex\n",
    "temp = pd.get_dummies(initData['Sex'])\n",
    "initData = pd.concat([initData, temp], axis=1).drop('Sex', axis=1)\n",
    "initData.rename(columns={'F': 'Female', 'M': 'Male','I': 'Infant'}, inplace = True)\n",
    "\n",
    "#Discretizing Ring Size\n",
    "initData['Ring-Range'] = pd.cut(initData['Rings'],[0,8,10,30],\n",
    "                                 labels=['1-8','9-10','11-30']) \n",
    "#initData['Ring-Range'] = initData['Ring-Range'].astype('uint8')\n",
    "del initData['Rings']\n",
    "initData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dfa073",
   "metadata": {},
   "source": [
    "I realize that 1-8, 9-10, and 11-30, are odd choices for ring ranges, but I wanted to ensure the number of entries per range was as similar as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd25e6a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ring-Range\n",
      "1-8      1407\n",
      "9-10     1323\n",
      "11-30    1447\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(initData.groupby(['Ring-Range']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc85ac",
   "metadata": {},
   "source": [
    "Next, I'll scale all the continuous variables, so that they rest between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74adfb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole-Weight</th>\n",
       "      <th>Shucked-Weight</th>\n",
       "      <th>Viscera-Weight</th>\n",
       "      <th>Shell-Weight</th>\n",
       "      <th>Female</th>\n",
       "      <th>Infant</th>\n",
       "      <th>Male</th>\n",
       "      <th>Ring-Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.084071</td>\n",
       "      <td>0.181335</td>\n",
       "      <td>0.150303</td>\n",
       "      <td>0.132324</td>\n",
       "      <td>0.147982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.066241</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.068261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614865</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.239065</td>\n",
       "      <td>0.171822</td>\n",
       "      <td>0.185648</td>\n",
       "      <td>0.207773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493243</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.182044</td>\n",
       "      <td>0.144250</td>\n",
       "      <td>0.149440</td>\n",
       "      <td>0.152965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.071897</td>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.051350</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length  Diameter    Height  Whole-Weight  Shucked-Weight  Viscera-Weight  \\\n",
       "0  0.513514  0.521008  0.084071      0.181335        0.150303        0.132324   \n",
       "1  0.371622  0.352941  0.079646      0.079157        0.066241        0.063199   \n",
       "2  0.614865  0.613445  0.119469      0.239065        0.171822        0.185648   \n",
       "3  0.493243  0.521008  0.110619      0.182044        0.144250        0.149440   \n",
       "4  0.344595  0.336134  0.070796      0.071897        0.059516        0.051350   \n",
       "\n",
       "   Shell-Weight  Female  Infant  Male Ring-Range  \n",
       "0      0.147982       0       0     1      11-30  \n",
       "1      0.068261       0       0     1        1-8  \n",
       "2      0.207773       1       0     0       9-10  \n",
       "3      0.152965       0       0     1       9-10  \n",
       "4      0.053313       0       1     0        1-8  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_vars = ['Length', 'Diameter', 'Height', 'Whole-Weight', 'Shucked-Weight', 'Viscera-Weight', 'Shell-Weight']\n",
    "for v in continuous_vars:\n",
    "    # Taken from: https://www.geeksforgeeks.org/normalize-a-column-in-pandas/\n",
    "    initData[v] = (initData[v]-initData[v].min())/(initData[v].max()-initData[v].min())\n",
    "\n",
    "initData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5647b0bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole-Weight</th>\n",
       "      <th>Shucked-Weight</th>\n",
       "      <th>Viscera-Weight</th>\n",
       "      <th>Shell-Weight</th>\n",
       "      <th>Female</th>\n",
       "      <th>Infant</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.606746</td>\n",
       "      <td>0.593078</td>\n",
       "      <td>0.123466</td>\n",
       "      <td>0.292808</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>0.236503</td>\n",
       "      <td>0.312904</td>\n",
       "      <td>0.321283</td>\n",
       "      <td>0.365813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.162288</td>\n",
       "      <td>0.166790</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.173681</td>\n",
       "      <td>0.149269</td>\n",
       "      <td>0.144324</td>\n",
       "      <td>0.138717</td>\n",
       "      <td>0.463731</td>\n",
       "      <td>0.467025</td>\n",
       "      <td>0.481715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.155658</td>\n",
       "      <td>0.124412</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.282451</td>\n",
       "      <td>0.225286</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.231689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.146018</td>\n",
       "      <td>0.407650</td>\n",
       "      <td>0.336920</td>\n",
       "      <td>0.332456</td>\n",
       "      <td>0.326358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole-Weight  Shucked-Weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
       "mean      0.606746     0.593078     0.123466      0.292808        0.241000   \n",
       "std       0.162288     0.166790     0.037015      0.173681        0.149269   \n",
       "min       0.000000     0.000000     0.000000      0.000000        0.000000   \n",
       "25%       0.506757     0.495798     0.101770      0.155658        0.124412   \n",
       "50%       0.635135     0.621849     0.123894      0.282451        0.225286   \n",
       "75%       0.729730     0.714286     0.146018      0.407650        0.336920   \n",
       "max       1.000000     1.000000     1.000000      1.000000        1.000000   \n",
       "\n",
       "       Viscera-Weight  Shell-Weight       Female       Infant         Male  \n",
       "count     4177.000000   4177.000000  4177.000000  4177.000000  4177.000000  \n",
       "mean         0.237121      0.236503     0.312904     0.321283     0.365813  \n",
       "std          0.144324      0.138717     0.463731     0.467025     0.481715  \n",
       "min          0.000000      0.000000     0.000000     0.000000     0.000000  \n",
       "25%          0.122449      0.128052     0.000000     0.000000     0.000000  \n",
       "50%          0.224490      0.231689     0.000000     0.000000     0.000000  \n",
       "75%          0.332456      0.326358     1.000000     1.000000     1.000000  \n",
       "max          1.000000      1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1636d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   Length          4177 non-null   float64 \n",
      " 1   Diameter        4177 non-null   float64 \n",
      " 2   Height          4177 non-null   float64 \n",
      " 3   Whole-Weight    4177 non-null   float64 \n",
      " 4   Shucked-Weight  4177 non-null   float64 \n",
      " 5   Viscera-Weight  4177 non-null   float64 \n",
      " 6   Shell-Weight    4177 non-null   float64 \n",
      " 7   Female          4177 non-null   uint8   \n",
      " 8   Infant          4177 non-null   uint8   \n",
      " 9   Male            4177 non-null   uint8   \n",
      " 10  Ring-Range      4177 non-null   category\n",
      "dtypes: category(1), float64(7), uint8(3)\n",
      "memory usage: 245.0 KB\n"
     ]
    }
   ],
   "source": [
    "initData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362c693",
   "metadata": {},
   "source": [
    "WIP, describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fbe62",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f31db40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "\n",
    "y = initData['Ring-Range'].values\n",
    "X = initData.drop('Ring-Range', axis=1).to_numpy()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# temp2 = y_train.to_numpy()\n",
    "# count1 = (temp2 == '1-8').sum()\n",
    "# count2 = (temp2 == '9-10').sum()\n",
    "# count3 = (temp2 == '11-30').sum()\n",
    "# print(count1, '|', count2, '|', count3)\n",
    "# temp2 = y_test.to_numpy()\n",
    "# count1 = (temp2 == '1-8').sum()\n",
    "# count2 = (temp2 == '9-10').sum()\n",
    "# count3 = (temp2 == '11-30').sum()\n",
    "# print(count1, '|', count2, '|', count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29cdc9",
   "metadata": {},
   "source": [
    "### Why an 80/20 split works best for my dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13073d",
   "metadata": {},
   "source": [
    "WIP, explain this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd241ce",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07deef",
   "metadata": {},
   "source": [
    "The below code is imported from the class notebook. The LogisticRegression class has been modified to accept a user-provided regression method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5562dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "            # add bacause maximizing \n",
    "        \n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "from scipy.optimize import minimize_scalar\n",
    "import copy\n",
    "from numpy import ma # (masked array) this has most numpy functions that work with NaN data.\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    # define custom line search for problem\n",
    "    def __init__(self, line_iters=0.0, **kwds):        \n",
    "        self.line_iters = line_iters\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(eta,X,y,w,grad,C):\n",
    "        wnew = w - grad*eta\n",
    "        g = expit(X @ wnew)\n",
    "        return -np.sum(ma.log(g[y==1]))-ma.sum(np.log(1-g[y==0])) + C*sum(wnew**2)\n",
    "    \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = -self._get_gradient(Xb,y)\n",
    "            # minimization inopposite direction\n",
    "            \n",
    "            # do line search in gradient direction, using scipy function\n",
    "            opts = {'maxiter':self.line_iters} # unclear exactly what this should be\n",
    "            res = minimize_scalar(self.objective_function, # objective function to optimize\n",
    "                                  bounds=(0,self.eta*10), #bounds to optimize\n",
    "                                  args=(Xb,y,self.w_,gradient,self.C), # additional argument for objective function\n",
    "                                  method='bounded', # bounded optimization for speed\n",
    "                                  options=opts) # set max iterations\n",
    "            \n",
    "            eta = res.x # get optimal learning rate\n",
    "            self.w_ -= gradient*eta # set new function values\n",
    "            # subtract to minimize\n",
    "                \n",
    "            \n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient\n",
    "\n",
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        # invert this because scipy minimizes, but we derived all formulas for maximzing\n",
    "        return -np.sum(ma.log(g[y==1]))-np.sum(ma.log(1-g[y==0])) + C*sum(w**2) \n",
    "        #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        gradient[1:] += -2 * w[1:] * C\n",
    "        return -gradient\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        self.w_ = self.w_.reshape((num_features,1))\n",
    "\n",
    "# Modified to include allow users to specify regression class, instead of only using VectorBinaryLogisticRegression.\n",
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.01, regMethod = BinaryLogisticRegression):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.regMethod = regMethod\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = self.regMethod(eta=self.eta, iterations=self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        print(self.predict_proba(X))\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    \n",
    "    def _add_bias(self,X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term'\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f85b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  either steepest ascent, stochastic gradient ascent, and {Newton's method/Quasi Newton methods}\n",
    "solverAlias = {'steepest':VectorBinaryLogisticRegression,\n",
    "               'stochastic':StochasticLogisticRegression,\n",
    "               'newton':HessianBinaryLogisticRegression}\n",
    "\n",
    "class CustomLogisiticRegressionWrapper:\n",
    "    def __init__(self, eta, iterations=100, solver='WIP', reg='Neither', cost = 0.01):\n",
    "        self.eta = eta\n",
    "        self.iter = iterations\n",
    "        self.C = cost\n",
    "        self.reg = reg\n",
    "        self.solv = LogisticRegression(eta=self.eta, iterations=self.iter, regMethod=solverAlias[solver])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self.solv.fit(X,y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.solv.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da33eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomLogisiticRegressionWrapper at 0x7feb42d80650>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(divide = 'ignore') \n",
    "lr = CustomLogisiticRegressionWrapper(eta=0.1,iterations=10,solver='newton')\n",
    "lr.fit(X_train,y_train)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1456305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80280166 0.18119414 0.20203233]\n",
      " [0.25377261 0.37663559 0.52549485]\n",
      " [0.32053695 0.37429877 0.46377348]\n",
      " [0.28861023 0.33403001 0.5508126 ]\n",
      " [0.76033902 0.19973827 0.22688292]\n",
      " [0.19164726 0.51635284 0.47249363]\n",
      " [0.1427754  0.63304534 0.4463771 ]\n",
      " [0.65643735 0.24255755 0.28680851]\n",
      " [0.26797126 0.39888171 0.50736458]\n",
      " [0.26639597 0.50877209 0.3956812 ]\n",
      " [0.59680791 0.28178659 0.29549516]\n",
      " [0.74547295 0.16627622 0.29175529]\n",
      " [0.12321104 0.79962598 0.28656336]\n",
      " [0.69339684 0.24378085 0.24687487]\n",
      " [0.29483356 0.3720808  0.49800035]\n",
      " [0.51512132 0.26737046 0.38278966]\n",
      " [0.45528505 0.33281971 0.36275519]\n",
      " [0.16266361 0.60628716 0.43245004]\n",
      " [0.31136063 0.36748856 0.48778802]\n",
      " [0.46561556 0.33903725 0.34536672]\n",
      " [0.4260994  0.3652962  0.37021423]\n",
      " [0.11884893 0.88313064 0.17863567]\n",
      " [0.67314533 0.19375482 0.33097843]\n",
      " [0.36075126 0.32579633 0.48385531]\n",
      " [0.27814946 0.43905588 0.44286929]\n",
      " [0.39438008 0.34442297 0.42396439]\n",
      " [0.40232758 0.36906154 0.38271247]\n",
      " [0.15559181 0.61406922 0.4427447 ]\n",
      " [0.80483378 0.18677206 0.1937818 ]\n",
      " [0.81283177 0.18540678 0.18669112]\n",
      " [0.54418355 0.29393636 0.33454524]\n",
      " [0.32420928 0.36294187 0.47947138]\n",
      " [0.30457886 0.30226612 0.5314754 ]\n",
      " [0.32120276 0.38171822 0.45295583]\n",
      " [0.20622016 0.54114875 0.44312442]\n",
      " [0.44399787 0.36928388 0.34064686]\n",
      " [0.48500773 0.30548733 0.37252457]\n",
      " [0.64803442 0.21997655 0.31660179]\n",
      " [0.41813849 0.36299779 0.37593726]\n",
      " [0.72302767 0.22688356 0.23340705]\n",
      " [0.42959836 0.37557967 0.34242976]\n",
      " [0.40867104 0.47885752 0.28247946]\n",
      " [0.22056946 0.53239603 0.42786611]\n",
      " [0.15935714 0.63208685 0.4022397 ]\n",
      " [0.32619837 0.34601359 0.49933916]\n",
      " [0.23787892 0.53796675 0.37138968]\n",
      " [0.50679953 0.28270861 0.36922151]\n",
      " [0.68294568 0.1749017  0.34399166]\n",
      " [0.23373436 0.40182622 0.5335217 ]\n",
      " [0.24972175 0.44536039 0.46660904]\n",
      " [0.22074903 0.51318374 0.4390168 ]\n",
      " [0.2323665  0.62509728 0.31702508]\n",
      " [0.36959139 0.38092515 0.41008914]\n",
      " [0.5203371  0.29212662 0.35592516]\n",
      " [0.09869366 0.76298204 0.35743147]\n",
      " [0.24287583 0.39042688 0.55791398]\n",
      " [0.69355037 0.23194177 0.26261376]\n",
      " [0.35751671 0.37882015 0.40003532]\n",
      " [0.20349023 0.57256303 0.41671974]\n",
      " [0.28546234 0.51981783 0.35711951]\n",
      " [0.57837098 0.26358372 0.33024172]\n",
      " [0.48309869 0.3218724  0.35951189]\n",
      " [0.86969905 0.16599562 0.14109797]\n",
      " [0.85262517 0.17546828 0.15124179]\n",
      " [0.76301097 0.17444927 0.2583747 ]\n",
      " [0.61283535 0.25387438 0.31613765]\n",
      " [0.60660408 0.25079332 0.31974967]\n",
      " [0.57005537 0.22035984 0.3985512 ]\n",
      " [0.23501002 0.42978605 0.51534704]\n",
      " [0.30940765 0.36730769 0.48753801]\n",
      " [0.23820964 0.48105071 0.44165506]\n",
      " [0.45219442 0.21227307 0.52165603]\n",
      " [0.65781201 0.19507093 0.34526449]\n",
      " [0.77452651 0.19321544 0.21997406]\n",
      " [0.59215358 0.25522861 0.33364522]\n",
      " [0.43935426 0.30110846 0.42882054]\n",
      " [0.69250802 0.177299   0.33007123]\n",
      " [0.12009205 0.78494735 0.30984765]\n",
      " [0.1625292  0.68494428 0.35120526]\n",
      " [0.20810843 0.70784544 0.27003787]\n",
      " [0.3912279  0.28509982 0.49409589]\n",
      " [0.26007732 0.41429527 0.49365549]\n",
      " [0.22306276 0.5277706  0.42084252]\n",
      " [0.2233097  0.61417662 0.33508643]\n",
      " [0.36033883 0.32193839 0.48354244]\n",
      " [0.46298781 0.31046102 0.39147781]\n",
      " [0.57720096 0.24821446 0.34751201]\n",
      " [0.32111333 0.40056486 0.43881982]\n",
      " [0.3183455  0.31083908 0.5392179 ]\n",
      " [0.53295464 0.2976003  0.33501585]\n",
      " [0.87784343 0.17504616 0.12330716]\n",
      " [0.48803947 0.27083132 0.40878127]\n",
      " [0.63634123 0.19603778 0.36826711]\n",
      " [0.78520261 0.19347275 0.20767017]\n",
      " [0.39469883 0.3056763  0.46964186]\n",
      " [0.11873706 0.79138571 0.28533926]\n",
      " [0.31042044 0.35814179 0.49508164]\n",
      " [0.68830861 0.18095616 0.33287572]\n",
      " [0.19661828 0.57841632 0.40774338]\n",
      " [0.13347819 0.71618382 0.3584736 ]\n",
      " [0.21020449 0.43710838 0.51879137]\n",
      " [0.35742088 0.37375691 0.43151389]\n",
      " [0.35803579 0.39880222 0.39717597]\n",
      " [0.29580943 0.42527796 0.44603935]\n",
      " [0.66067562 0.21954585 0.30228333]\n",
      " [0.23330732 0.45891358 0.4688667 ]\n",
      " [0.24960934 0.42932868 0.49050333]\n",
      " [0.36015677 0.29934219 0.51031944]\n",
      " [0.7243834  0.19046736 0.28106647]\n",
      " [0.35136655 0.36202952 0.45121388]\n",
      " [0.40694344 0.37307166 0.3822902 ]\n",
      " [0.60482291 0.2652003  0.30841273]\n",
      " [0.44317561 0.26363358 0.47400477]\n",
      " [0.44013263 0.29410249 0.43427402]\n",
      " [0.73953236 0.21845328 0.22539269]\n",
      " [0.45161009 0.30438737 0.38775227]\n",
      " [0.64113157 0.206322   0.34675525]\n",
      " [0.20309644 0.53365627 0.44303665]\n",
      " [0.37469835 0.41216431 0.35993554]\n",
      " [0.28542047 0.39794884 0.49019892]\n",
      " [0.18784032 0.63903298 0.36473163]\n",
      " [0.35546156 0.45563098 0.32828751]\n",
      " [0.70364347 0.19194164 0.29911761]\n",
      " [0.56670606 0.25258741 0.35566887]\n",
      " [0.78671088 0.20618771 0.19085386]\n",
      " [0.59071872 0.28517091 0.29683344]\n",
      " [0.62086708 0.26567916 0.2933835 ]\n",
      " [0.4803954  0.27432761 0.40568477]\n",
      " [0.64704007 0.23453255 0.29986486]\n",
      " [0.21427119 0.53469597 0.43824174]\n",
      " [0.22918485 0.50137974 0.44186883]\n",
      " [0.27550535 0.44960448 0.44348438]\n",
      " [0.27663987 0.55840704 0.32768312]\n",
      " [0.71371661 0.16685918 0.32097985]\n",
      " [0.14370712 0.65988563 0.38349073]\n",
      " [0.3323595  0.35109208 0.48435766]\n",
      " [0.44334144 0.31741811 0.40576099]\n",
      " [0.59658153 0.2368765  0.34801721]\n",
      " [0.52429003 0.33961762 0.29344285]\n",
      " [0.85997816 0.17318087 0.14606627]\n",
      " [0.34893156 0.31808894 0.51387672]\n",
      " [0.28492026 0.36669428 0.52812532]\n",
      " [0.38793713 0.34035067 0.42564704]\n",
      " [0.39036031 0.40981073 0.35075486]\n",
      " [0.21404669 0.44186492 0.52654458]\n",
      " [0.13758084 0.84087107 0.20152869]\n",
      " [0.41068307 0.33046494 0.41855374]\n",
      " [0.66776416 0.21756495 0.30097458]\n",
      " [0.81302136 0.17830217 0.19520045]\n",
      " [0.48382728 0.30435849 0.37607341]\n",
      " [0.14925428 0.63275589 0.43141772]\n",
      " [0.31262537 0.41228569 0.44155546]\n",
      " [0.26961213 0.44736837 0.45470864]\n",
      " [0.25244757 0.42899516 0.49647127]\n",
      " [0.65625474 0.23436837 0.2954105 ]\n",
      " [0.73426909 0.19493764 0.26160079]\n",
      " [0.18969576 0.58552166 0.41413462]\n",
      " [0.70532841 0.22016057 0.25940475]\n",
      " [0.2770665  0.43435422 0.44947438]\n",
      " [0.13642175 0.81085396 0.23970846]\n",
      " [0.29514873 0.42012264 0.44444053]\n",
      " [0.28751338 0.37962044 0.50887882]\n",
      " [0.34435861 0.33285366 0.48279785]\n",
      " [0.5044977  0.26189683 0.41828184]\n",
      " [0.60680923 0.26433054 0.30549378]\n",
      " [0.1556741  0.64022562 0.40624694]\n",
      " [0.33100132 0.34434677 0.48763655]\n",
      " [0.82646665 0.17960113 0.17770633]\n",
      " [0.65887216 0.14558635 0.41601236]\n",
      " [0.24546994 0.48340143 0.43791312]\n",
      " [0.30806195 0.36877582 0.49253152]\n",
      " [0.42875414 0.41615013 0.29256008]\n",
      " [0.48172553 0.31295979 0.36986708]\n",
      " [0.34777408 0.31660419 0.50330753]\n",
      " [0.22601626 0.4374817  0.50500542]\n",
      " [0.26927669 0.39332896 0.50316783]\n",
      " [0.60563333 0.24967472 0.32324849]\n",
      " [0.25014428 0.44705007 0.48265395]\n",
      " [0.75643745 0.19643949 0.23576317]\n",
      " [0.34574521 0.37992944 0.4354052 ]\n",
      " [0.7009766  0.21760367 0.26705721]\n",
      " [0.24512735 0.50033063 0.4241927 ]\n",
      " [0.70668712 0.23208096 0.24925461]\n",
      " [0.12471144 0.75817512 0.34828341]\n",
      " [0.15222544 0.73823208 0.30180966]\n",
      " [0.20869764 0.49629179 0.47657195]\n",
      " [0.2971702  0.52314382 0.3389646 ]\n",
      " [0.14844    0.57506678 0.49567364]\n",
      " [0.17324861 0.6184528  0.40569456]\n",
      " [0.14646352 0.57801842 0.47063552]\n",
      " [0.23424472 0.47274801 0.45320524]\n",
      " [0.40935077 0.33402122 0.4048485 ]\n",
      " [0.31690814 0.35516954 0.5001121 ]\n",
      " [0.26580273 0.44021624 0.45070207]\n",
      " [0.24759512 0.43132997 0.4885598 ]\n",
      " [0.86041088 0.17870242 0.1398449 ]\n",
      " [0.18382034 0.50360784 0.4880595 ]\n",
      " [0.38546681 0.28823058 0.50718093]\n",
      " [0.37830108 0.37769932 0.39443903]\n",
      " [0.29627787 0.51897567 0.34474335]\n",
      " [0.19436703 0.5565937  0.43054657]\n",
      " [0.55554053 0.2369405  0.38506229]\n",
      " [0.20955206 0.47984715 0.48496512]\n",
      " [0.34625926 0.3513486  0.46740395]\n",
      " [0.36716142 0.42617821 0.34709274]\n",
      " [0.16138809 0.63782849 0.39118631]\n",
      " [0.20978272 0.53408551 0.41577538]\n",
      " [0.23809923 0.47439729 0.44530109]\n",
      " [0.36960782 0.28909822 0.51745783]\n",
      " [0.42245541 0.25440898 0.51818792]\n",
      " [0.22321316 0.57780247 0.36939002]\n",
      " [0.18263968 0.520052   0.4804132 ]\n",
      " [0.41447231 0.32637886 0.4191057 ]\n",
      " [0.2864996  0.42059646 0.45707754]\n",
      " [0.2631437  0.4562763  0.45238524]\n",
      " [0.20948841 0.42586269 0.54560345]\n",
      " [0.46725588 0.29508108 0.3958599 ]\n",
      " [0.81640986 0.20316488 0.16147908]\n",
      " [0.20327986 0.54455204 0.43249276]\n",
      " [0.71689116 0.2185374  0.24972451]\n",
      " [0.16861479 0.23780987 0.76398289]\n",
      " [0.1528069  0.67218119 0.36243692]\n",
      " [0.29225524 0.40509181 0.46067295]\n",
      " [0.26739531 0.37149421 0.53820394]\n",
      " [0.15694943 0.67261339 0.37891544]\n",
      " [0.40429047 0.33548485 0.42203757]\n",
      " [0.26437566 0.43150702 0.46615918]\n",
      " [0.31081709 0.37670345 0.46941438]\n",
      " [0.24610142 0.49142005 0.41937848]\n",
      " [0.82227788 0.16798702 0.19677586]\n",
      " [0.65335024 0.24280195 0.28588882]\n",
      " [0.47335433 0.32181576 0.36798945]\n",
      " [0.71548962 0.17355587 0.31227282]\n",
      " [0.21929195 0.62926161 0.33915513]\n",
      " [0.59642581 0.21465313 0.38015023]\n",
      " [0.59434103 0.25503909 0.32990558]\n",
      " [0.15376299 0.62855584 0.41855193]\n",
      " [0.4168634  0.35621551 0.38952899]\n",
      " [0.53326012 0.29471002 0.34376287]\n",
      " [0.16670271 0.62227263 0.41126306]\n",
      " [0.18069564 0.5013561  0.50036898]\n",
      " [0.26974621 0.59836119 0.30060686]\n",
      " [0.40080779 0.36198712 0.40548248]\n",
      " [0.09588955 0.82726769 0.28552333]\n",
      " [0.52820204 0.28397245 0.35054664]\n",
      " [0.41391297 0.30545836 0.44934776]\n",
      " [0.38694236 0.32371309 0.45612449]\n",
      " [0.8277676  0.18205518 0.1738807 ]\n",
      " [0.54397891 0.29735006 0.31830378]\n",
      " [0.18860701 0.5834786  0.40231747]\n",
      " [0.60957836 0.22855933 0.3413504 ]\n",
      " [0.42570542 0.37116307 0.35542771]\n",
      " [0.385382   0.25530731 0.53652667]\n",
      " [0.6120779  0.24795274 0.31651487]\n",
      " [0.19555132 0.47981626 0.51448304]\n",
      " [0.10909701 0.76030148 0.34177937]\n",
      " [0.27521515 0.46693861 0.42054795]\n",
      " [0.45556413 0.341267   0.36367085]\n",
      " [0.17387768 0.60544637 0.41680519]\n",
      " [0.19135975 0.54484942 0.46326256]\n",
      " [0.36569511 0.29550578 0.50901085]\n",
      " [0.78324241 0.21435121 0.1839369 ]\n",
      " [0.68079753 0.20911928 0.2999222 ]\n",
      " [0.16527745 0.51984024 0.50456993]\n",
      " [0.07574921 0.92258646 0.16821841]\n",
      " [0.49693629 0.34616439 0.31327949]\n",
      " [0.51011815 0.25120804 0.42001865]\n",
      " [0.60364525 0.23316867 0.34280583]\n",
      " [0.17563267 0.57880353 0.44101758]\n",
      " [0.24842006 0.64183481 0.28645127]\n",
      " [0.12997742 0.82203799 0.25814008]\n",
      " [0.83671921 0.18297029 0.1623787 ]\n",
      " [0.62217898 0.24304405 0.32219144]\n",
      " [0.18115142 0.54936301 0.46178661]\n",
      " [0.11516415 0.91344429 0.13748037]\n",
      " [0.20025149 0.55084179 0.42815567]\n",
      " [0.15634549 0.63440518 0.41598453]\n",
      " [0.30965524 0.32725638 0.53608633]\n",
      " [0.32972274 0.38727838 0.44692419]\n",
      " [0.35870128 0.40412911 0.40066385]\n",
      " [0.13464946 0.67862356 0.40268127]\n",
      " [0.36755569 0.34229403 0.46037091]\n",
      " [0.2891231  0.45623945 0.42376336]\n",
      " [0.43489733 0.34459492 0.37906693]\n",
      " [0.30491579 0.48690148 0.38521053]\n",
      " [0.182156   0.58000439 0.43143603]\n",
      " [0.44689235 0.2533213  0.48743659]\n",
      " [0.70150456 0.20314437 0.28762406]\n",
      " [0.193458   0.64989102 0.34590244]\n",
      " [0.25561913 0.70878595 0.2102424 ]\n",
      " [0.33101181 0.32625133 0.50824122]\n",
      " [0.74663891 0.19524552 0.24802736]\n",
      " [0.2005613  0.48309901 0.50063831]\n",
      " [0.7518762  0.18215016 0.26188487]\n",
      " [0.48346381 0.28786724 0.38278206]\n",
      " [0.85213181 0.16074713 0.16785145]\n",
      " [0.08836409 0.85641527 0.26407233]\n",
      " [0.57576994 0.23136221 0.37632256]\n",
      " [0.3089315  0.36741524 0.50004236]\n",
      " [0.36398627 0.30865273 0.49806018]\n",
      " [0.56752449 0.27890683 0.33177788]\n",
      " [0.24792688 0.41006508 0.51922896]\n",
      " [0.66139897 0.19199028 0.34346698]\n",
      " [0.75780138 0.20140862 0.22823109]\n",
      " [0.72056984 0.20624758 0.26367956]\n",
      " [0.49692266 0.30881451 0.3590512 ]\n",
      " [0.34982533 0.32288859 0.50041006]\n",
      " [0.10184691 0.81700057 0.29599847]\n",
      " [0.49178446 0.2962385  0.38577784]\n",
      " [0.29802969 0.34227054 0.51556416]\n",
      " [0.18572589 0.6566843  0.3367158 ]\n",
      " [0.44245377 0.3584303  0.34918402]\n",
      " [0.07223365 0.86917501 0.27857721]\n",
      " [0.17340236 0.706845   0.31108557]\n",
      " [0.08751368 0.86152801 0.26678088]\n",
      " [0.3745236  0.26249514 0.52989062]\n",
      " [0.36881088 0.31572886 0.48486471]\n",
      " [0.26861538 0.36836599 0.49995296]\n",
      " [0.41323041 0.39573713 0.34345999]\n",
      " [0.53644089 0.23250638 0.41313438]\n",
      " [0.20229249 0.60309264 0.37841951]\n",
      " [0.21918677 0.52143358 0.42272092]\n",
      " [0.2344205  0.48081608 0.45888166]\n",
      " [0.46113124 0.31598212 0.3915739 ]\n",
      " [0.39688856 0.33999715 0.42203835]\n",
      " [0.16145634 0.69627608 0.33686072]\n",
      " [0.69173201 0.19598013 0.3087587 ]\n",
      " [0.34047241 0.34421794 0.48362095]\n",
      " [0.11765967 0.80336979 0.28438125]\n",
      " [0.2180933  0.51350106 0.44017836]\n",
      " [0.25042461 0.41352483 0.49463628]\n",
      " [0.26624768 0.43794112 0.46766421]\n",
      " [0.21489654 0.48509582 0.47817529]\n",
      " [0.62855097 0.20158252 0.3650517 ]\n",
      " [0.4182086  0.33614683 0.39693384]\n",
      " [0.17635312 0.54688956 0.47259218]\n",
      " [0.26908195 0.31710085 0.58118694]\n",
      " [0.55517854 0.24341146 0.37788408]\n",
      " [0.10137384 0.79854761 0.3322059 ]\n",
      " [0.33150206 0.506391   0.30561891]\n",
      " [0.37259416 0.3225129  0.47888349]\n",
      " [0.17705261 0.50206821 0.50558213]\n",
      " [0.56030689 0.21910297 0.40273393]\n",
      " [0.4027917  0.34206032 0.3820022 ]\n",
      " [0.36964117 0.28970599 0.51102949]\n",
      " [0.54170171 0.25920559 0.36640707]\n",
      " [0.27726354 0.50011278 0.39163505]\n",
      " [0.37501457 0.28925015 0.50955012]\n",
      " [0.65209755 0.23523469 0.29185037]\n",
      " [0.32262383 0.33583959 0.5087401 ]\n",
      " [0.30593805 0.26368709 0.62784204]\n",
      " [0.40615893 0.33646612 0.40740706]\n",
      " [0.79719749 0.17942159 0.21180675]\n",
      " [0.45966777 0.24613677 0.48381323]\n",
      " [0.34747848 0.25642672 0.5805532 ]\n",
      " [0.30872941 0.3702112  0.49068754]\n",
      " [0.76516329 0.17458895 0.25192705]\n",
      " [0.16597381 0.80481641 0.20583996]\n",
      " [0.54077952 0.28939486 0.34136258]\n",
      " [0.26357008 0.40528133 0.49367971]\n",
      " [0.6626995  0.19614513 0.33735166]\n",
      " [0.50410579 0.30916644 0.34165876]\n",
      " [0.66375581 0.23204009 0.28531135]\n",
      " [0.373624   0.37811224 0.40628138]\n",
      " [0.4369612  0.3190038  0.40750168]\n",
      " [0.71585525 0.22505236 0.23933215]\n",
      " [0.47460427 0.3299887  0.34757168]\n",
      " [0.19167893 0.53037225 0.46397638]\n",
      " [0.73126183 0.19835283 0.25748314]\n",
      " [0.61830422 0.22791199 0.33742807]\n",
      " [0.62168086 0.23821589 0.31997467]\n",
      " [0.1142004  0.85790097 0.2082615 ]\n",
      " [0.50400256 0.23867778 0.45047777]\n",
      " [0.20538167 0.55122596 0.42276583]\n",
      " [0.52299951 0.28214195 0.36760739]\n",
      " [0.19529084 0.69839701 0.29138123]\n",
      " [0.84810089 0.17981452 0.15206316]\n",
      " [0.83460434 0.18635302 0.1611504 ]\n",
      " [0.42108608 0.48100699 0.26008679]\n",
      " [0.26167205 0.51156103 0.39076272]\n",
      " [0.13860473 0.63293277 0.45886857]\n",
      " [0.24719422 0.53224454 0.38830687]\n",
      " [0.30878358 0.40955687 0.44210717]\n",
      " [0.14590873 0.67656705 0.36452665]\n",
      " [0.56276957 0.22334367 0.39879087]\n",
      " [0.66280174 0.20537808 0.326291  ]\n",
      " [0.41856275 0.32339616 0.41996367]\n",
      " [0.49233627 0.25525937 0.42380691]\n",
      " [0.6546714  0.23226197 0.29745847]\n",
      " [0.20724972 0.66360038 0.32545909]\n",
      " [0.65580566 0.20884693 0.32684282]\n",
      " [0.59090239 0.24913951 0.3354139 ]\n",
      " [0.20139853 0.52130433 0.4537655 ]\n",
      " [0.20103444 0.68927436 0.29212052]\n",
      " [0.69903485 0.20754015 0.2815952 ]\n",
      " [0.13296055 0.7975833  0.25882362]\n",
      " [0.38789663 0.34113583 0.43466481]\n",
      " [0.39881348 0.34273501 0.4011734 ]\n",
      " [0.70189803 0.21277044 0.27278445]\n",
      " [0.39064278 0.26022437 0.52552561]\n",
      " [0.1897283  0.56320091 0.4325814 ]\n",
      " [0.31525383 0.34855276 0.50711946]\n",
      " [0.20911797 0.56193269 0.41565196]\n",
      " [0.18281724 0.49091101 0.5169364 ]\n",
      " [0.54575337 0.22766845 0.40941353]\n",
      " [0.4256099  0.34628018 0.37899918]\n",
      " [0.2378066  0.43810749 0.49831711]\n",
      " [0.20187805 0.45763253 0.50854363]\n",
      " [0.24450302 0.47816842 0.45268047]\n",
      " [0.3531619  0.2933087  0.52000794]\n",
      " [0.23738725 0.50979458 0.43079815]\n",
      " [0.63222064 0.21716745 0.33898728]\n",
      " [0.74634269 0.20311057 0.23778078]\n",
      " [0.1834539  0.62987648 0.37697918]\n",
      " [0.38684604 0.32914377 0.42285684]\n",
      " [0.17128704 0.55106045 0.47770168]\n",
      " [0.36080895 0.39698581 0.40222605]\n",
      " [0.42547159 0.34590424 0.37892418]\n",
      " [0.28893663 0.38762106 0.48979526]\n",
      " [0.17491918 0.68735042 0.33099724]\n",
      " [0.26053358 0.52244053 0.3847303 ]\n",
      " [0.32033022 0.53105851 0.28254933]\n",
      " [0.31446197 0.43688945 0.40750968]\n",
      " [0.18783542 0.50956456 0.48150518]\n",
      " [0.43386392 0.26945587 0.49165394]\n",
      " [0.6474146  0.2345341  0.30680773]\n",
      " [0.55008261 0.28321494 0.33856384]\n",
      " [0.21273834 0.40776007 0.55620352]\n",
      " [0.09588566 0.90082696 0.17069811]\n",
      " [0.16975661 0.58950027 0.43062443]\n",
      " [0.23551884 0.46634282 0.46363961]\n",
      " [0.84922031 0.17225822 0.15919323]\n",
      " [0.33898802 0.379316   0.43946641]\n",
      " [0.55352488 0.2782198  0.34352948]\n",
      " [0.76857424 0.19582734 0.22320545]\n",
      " [0.13181937 0.68986741 0.39856966]\n",
      " [0.60121525 0.23917484 0.33658103]\n",
      " [0.29381739 0.49776723 0.36742569]\n",
      " [0.35072179 0.35593236 0.45773863]\n",
      " [0.58056418 0.2612167  0.32851628]\n",
      " [0.43519679 0.29350368 0.4433598 ]\n",
      " [0.50575108 0.2708162  0.39051445]\n",
      " [0.70427688 0.23442257 0.24905216]\n",
      " [0.73667423 0.18726744 0.2714638 ]\n",
      " [0.20669287 0.44880474 0.49206915]\n",
      " [0.29727568 0.32364213 0.55467423]\n",
      " [0.21037231 0.45958037 0.5145198 ]\n",
      " [0.3505274  0.31343616 0.50770738]\n",
      " [0.80616678 0.20729717 0.17321508]\n",
      " [0.20148341 0.54984784 0.4294494 ]\n",
      " [0.20312244 0.46626943 0.50480361]\n",
      " [0.10518582 0.88111197 0.19089894]\n",
      " [0.16621775 0.71161273 0.31128295]\n",
      " [0.4628143  0.30076717 0.3887114 ]\n",
      " [0.18051367 0.54634651 0.46250823]\n",
      " [0.70744951 0.2140961  0.26411302]\n",
      " [0.55368056 0.26386982 0.36179633]\n",
      " [0.25924076 0.74377118 0.17818154]\n",
      " [0.14506348 0.61298732 0.44658546]\n",
      " [0.30416271 0.398022   0.46023444]\n",
      " [0.27614787 0.34087019 0.5561235 ]\n",
      " [0.66140101 0.23142463 0.28730264]\n",
      " [0.22008798 0.66197274 0.30177321]\n",
      " [0.35406048 0.42513388 0.35017601]\n",
      " [0.7718377  0.17567337 0.24635504]\n",
      " [0.23551768 0.45137207 0.47010248]\n",
      " [0.70194913 0.20904331 0.27620016]\n",
      " [0.27659104 0.40267041 0.48814856]\n",
      " [0.29308369 0.4085059  0.47210077]\n",
      " [0.31181385 0.30596134 0.56633568]\n",
      " [0.13752129 0.68516397 0.39691809]\n",
      " [0.47158361 0.3737237  0.29458887]\n",
      " [0.24242927 0.41120921 0.52428658]\n",
      " [0.33111576 0.4214583  0.40721525]\n",
      " [0.85762724 0.17246451 0.14948091]\n",
      " [0.23160919 0.49611747 0.45151564]\n",
      " [0.30045971 0.35843881 0.46881011]\n",
      " [0.36397195 0.40510796 0.39123074]\n",
      " [0.20916211 0.48995947 0.49135716]\n",
      " [0.22144753 0.4559033  0.48827991]\n",
      " [0.10769029 0.75095429 0.35646518]\n",
      " [0.67977646 0.22083576 0.28298488]\n",
      " [0.15104279 0.67928351 0.3675636 ]\n",
      " [0.30006028 0.32296579 0.55083337]\n",
      " [0.3088022  0.42289994 0.42381306]\n",
      " [0.79214474 0.18452781 0.21160605]\n",
      " [0.27655911 0.3640225  0.5307058 ]\n",
      " [0.82091418 0.17980525 0.18376161]\n",
      " [0.22819729 0.52418961 0.42722421]\n",
      " [0.21924683 0.51796677 0.43772256]\n",
      " [0.70525343 0.23777663 0.24278765]\n",
      " [0.33965329 0.30369034 0.52381014]\n",
      " [0.15650331 0.55492706 0.50221794]\n",
      " [0.60269891 0.27286948 0.29646063]\n",
      " [0.30551353 0.46401278 0.38644018]\n",
      " [0.27046203 0.47975582 0.42549232]\n",
      " [0.43278609 0.33789349 0.39211493]\n",
      " [0.8864855  0.16791906 0.11898019]\n",
      " [0.83968159 0.17829592 0.16433424]\n",
      " [0.31962633 0.35963074 0.48500947]\n",
      " [0.41785299 0.29053618 0.46810229]\n",
      " [0.24813116 0.57437918 0.35480935]\n",
      " [0.47210261 0.33738901 0.34865086]\n",
      " [0.18589031 0.69928957 0.30380718]\n",
      " [0.81704337 0.18038784 0.18747007]\n",
      " [0.35131741 0.42786621 0.35608221]\n",
      " [0.16130839 0.62551136 0.42215701]\n",
      " [0.52503663 0.30903603 0.33141073]\n",
      " [0.25480255 0.48981246 0.41172844]\n",
      " [0.37048519 0.29635215 0.50313674]\n",
      " [0.86165794 0.16453433 0.15085182]\n",
      " [0.29239635 0.43567955 0.43066953]\n",
      " [0.51054216 0.27196097 0.38109608]\n",
      " [0.74446035 0.20591489 0.23307922]\n",
      " [0.39755354 0.29072998 0.48377161]\n",
      " [0.55134319 0.25702531 0.3657202 ]\n",
      " [0.15531731 0.64508794 0.39818372]\n",
      " [0.16963015 0.63821455 0.40174546]\n",
      " [0.16354208 0.59131561 0.46482946]\n",
      " [0.35990846 0.29975629 0.50874938]\n",
      " [0.23417399 0.53457496 0.39733477]\n",
      " [0.126389   0.74785412 0.34075006]\n",
      " [0.79215713 0.19716854 0.19622282]\n",
      " [0.18654351 0.65777635 0.34248706]\n",
      " [0.3500881  0.34547125 0.47339008]\n",
      " [0.62213539 0.25322257 0.30017747]\n",
      " [0.18331658 0.56707352 0.44251737]\n",
      " [0.20248998 0.4578961  0.51336321]\n",
      " [0.25414919 0.42106028 0.49345551]\n",
      " [0.32252417 0.41738264 0.41413067]\n",
      " [0.30402452 0.37973007 0.47357717]\n",
      " [0.60649599 0.24973725 0.31800615]\n",
      " [0.63165324 0.22671909 0.32465459]\n",
      " [0.42844285 0.17721885 0.62466613]\n",
      " [0.28812839 0.36051799 0.51741955]\n",
      " [0.38851734 0.35957258 0.41275114]\n",
      " [0.67860499 0.24480648 0.25512343]\n",
      " [0.41922057 0.36378453 0.36833297]\n",
      " [0.35104124 0.34457677 0.47135205]\n",
      " [0.21162174 0.61945341 0.35403413]\n",
      " [0.59578881 0.26655274 0.3136847 ]\n",
      " [0.16205539 0.59470953 0.43701812]\n",
      " [0.21001676 0.42390091 0.54171156]\n",
      " [0.60464761 0.22734318 0.34882342]\n",
      " [0.43506307 0.29084754 0.43140838]\n",
      " [0.3490948  0.33111953 0.47920611]\n",
      " [0.51211865 0.32376161 0.32131054]\n",
      " [0.28138638 0.55965218 0.29775665]\n",
      " [0.36316486 0.29367878 0.51730651]\n",
      " [0.10910347 0.88416605 0.18350482]\n",
      " [0.03946565 0.98004252 0.07336693]\n",
      " [0.27482452 0.44657933 0.45497879]\n",
      " [0.36570817 0.32206166 0.48454381]\n",
      " [0.2972242  0.4151789  0.45324284]\n",
      " [0.20256111 0.59946865 0.38573279]\n",
      " [0.55807047 0.23462928 0.38831694]\n",
      " [0.63416374 0.2157823  0.3367754 ]\n",
      " [0.29625919 0.46087596 0.40530372]\n",
      " [0.70986454 0.18219475 0.3051864 ]\n",
      " [0.15003426 0.72028326 0.32943902]\n",
      " [0.24504529 0.57433062 0.35437782]\n",
      " [0.30635702 0.43037914 0.42215007]\n",
      " [0.21942171 0.57943286 0.38063662]\n",
      " [0.11755215 0.83015723 0.25051167]\n",
      " [0.22924532 0.52528402 0.42378713]\n",
      " [0.26625413 0.41093783 0.49183283]\n",
      " [0.36749378 0.29628986 0.50221387]\n",
      " [0.34138751 0.41824213 0.39031216]\n",
      " [0.28859659 0.40181262 0.47018351]\n",
      " [0.43506251 0.26149858 0.48439231]\n",
      " [0.62823768 0.24886847 0.29816856]\n",
      " [0.35932133 0.33427183 0.47276629]\n",
      " [0.19569278 0.5561811  0.436873  ]\n",
      " [0.38085975 0.28618949 0.49701303]\n",
      " [0.1991529  0.52106429 0.46212469]\n",
      " [0.29761074 0.44486205 0.4173907 ]\n",
      " [0.32550285 0.26911506 0.58925827]\n",
      " [0.53982079 0.22889402 0.42014248]\n",
      " [0.08367071 0.84294898 0.30780605]\n",
      " [0.32020632 0.30320946 0.5584525 ]\n",
      " [0.55477755 0.22391874 0.40718334]\n",
      " [0.29631538 0.43568758 0.42809925]\n",
      " [0.43233876 0.306871   0.42945139]\n",
      " [0.4148243  0.22399985 0.55917874]\n",
      " [0.12546102 0.74133214 0.36172296]\n",
      " [0.36344733 0.38358312 0.41576087]\n",
      " [0.33306374 0.36013171 0.47366815]\n",
      " [0.42662063 0.32868572 0.39637406]\n",
      " [0.53325293 0.28181164 0.35719018]\n",
      " [0.54591256 0.27403612 0.3453268 ]\n",
      " [0.62840517 0.24158445 0.30886938]\n",
      " [0.41534428 0.13820613 0.66053168]\n",
      " [0.24117421 0.42374147 0.51076822]\n",
      " [0.38697849 0.37082916 0.40510662]\n",
      " [0.07310469 0.89215789 0.24295784]\n",
      " [0.60823352 0.23472356 0.34600143]\n",
      " [0.55630088 0.28671421 0.32419389]\n",
      " [0.14145673 0.63521164 0.43497372]\n",
      " [0.40205847 0.37222211 0.36688512]\n",
      " [0.24949892 0.47449298 0.42182346]\n",
      " [0.24773749 0.43813007 0.48814999]\n",
      " [0.34387393 0.52119059 0.304487  ]\n",
      " [0.24371256 0.46049691 0.46588644]\n",
      " [0.2539728  0.45139051 0.45980577]\n",
      " [0.80915475 0.17941706 0.19841411]\n",
      " [0.72085528 0.20069501 0.26785625]\n",
      " [0.33672874 0.39867441 0.41988062]\n",
      " [0.3283861  0.33991042 0.50308793]\n",
      " [0.17483036 0.7339641  0.27094281]\n",
      " [0.35467068 0.35564566 0.43955718]\n",
      " [0.67760031 0.19843609 0.32055154]\n",
      " [0.24023448 0.47097863 0.4702522 ]\n",
      " [0.35324731 0.37729914 0.42956227]\n",
      " [0.17048554 0.5232316  0.49473533]\n",
      " [0.31901825 0.43264085 0.40283375]\n",
      " [0.25421808 0.5934144  0.31514049]\n",
      " [0.39856361 0.37995227 0.37337689]\n",
      " [0.54282475 0.2959246  0.32251639]\n",
      " [0.80253718 0.18021862 0.20588773]\n",
      " [0.40871235 0.33081511 0.40872558]\n",
      " [0.29886335 0.34233172 0.51434319]\n",
      " [0.40919693 0.33831815 0.40934682]\n",
      " [0.27011412 0.5661112  0.33382448]\n",
      " [0.74572979 0.21962248 0.22303771]\n",
      " [0.48065942 0.32632554 0.34766782]\n",
      " [0.30779144 0.53148603 0.30692564]\n",
      " [0.73601683 0.19484619 0.25946303]\n",
      " [0.18546915 0.62345168 0.39564134]\n",
      " [0.2151241  0.65450001 0.31364274]\n",
      " [0.3300581  0.31245158 0.52963693]\n",
      " [0.20144298 0.6815376  0.30443808]\n",
      " [0.28300644 0.42416515 0.45744854]\n",
      " [0.6243004  0.23224931 0.32288268]\n",
      " [0.33353949 0.42907128 0.39097964]\n",
      " [0.50322741 0.27941096 0.38431973]\n",
      " [0.22691402 0.53975288 0.40451918]\n",
      " [0.51379019 0.25315851 0.40598155]\n",
      " [0.17923432 0.6470369  0.37511941]\n",
      " [0.74585359 0.20866029 0.23252438]\n",
      " [0.27329948 0.35992304 0.5375123 ]\n",
      " [0.20011173 0.51147692 0.48589353]\n",
      " [0.70700832 0.19294921 0.2887536 ]\n",
      " [0.20472376 0.53217686 0.45864127]\n",
      " [0.21623219 0.55626902 0.39947948]\n",
      " [0.46598083 0.37407434 0.30526425]\n",
      " [0.71108879 0.20750208 0.26867061]\n",
      " [0.2671937  0.30024187 0.61276933]\n",
      " [0.51880403 0.23935734 0.40602719]\n",
      " [0.2398956  0.43755627 0.46341481]\n",
      " [0.19538515 0.52950494 0.46800584]\n",
      " [0.61102865 0.22596008 0.33926729]\n",
      " [0.13280711 0.72627534 0.35383387]\n",
      " [0.76857712 0.19169174 0.22897085]\n",
      " [0.43371518 0.31019392 0.41539394]\n",
      " [0.23399755 0.49357043 0.44062135]\n",
      " [0.23318816 0.4675191  0.46396712]\n",
      " [0.64392135 0.22403187 0.3166145 ]\n",
      " [0.36044064 0.40755001 0.39156996]\n",
      " [0.2508932  0.53065046 0.3806192 ]\n",
      " [0.24548991 0.62967701 0.30072   ]\n",
      " [0.27742792 0.4962566  0.38004748]\n",
      " [0.74392556 0.19318616 0.25818602]\n",
      " [0.27105217 0.6049642  0.29616995]\n",
      " [0.5803939  0.31338482 0.27057478]\n",
      " [0.16718649 0.66163601 0.36454739]\n",
      " [0.22435453 0.55300426 0.39584686]\n",
      " [0.14324135 0.69862063 0.36622839]\n",
      " [0.47603986 0.25830992 0.43755082]\n",
      " [0.57158689 0.24947876 0.35598021]\n",
      " [0.29397188 0.40213753 0.47009918]\n",
      " [0.23862601 0.44796568 0.47002002]\n",
      " [0.15736294 0.7235604  0.32183193]\n",
      " [0.19920199 0.47351069 0.52606877]\n",
      " [0.20705763 0.47647093 0.49395551]\n",
      " [0.62470275 0.23021029 0.33480743]\n",
      " [0.30591325 0.18695888 0.7372552 ]\n",
      " [0.21399977 0.41439957 0.56726655]\n",
      " [0.42993195 0.32858293 0.40974131]\n",
      " [0.39218679 0.43481406 0.31962182]\n",
      " [0.40826181 0.36378006 0.37389908]\n",
      " [0.4727047  0.28217273 0.40576903]\n",
      " [0.67828095 0.13510815 0.42622829]\n",
      " [0.34089871 0.45155235 0.35365086]\n",
      " [0.76301633 0.19854438 0.22395039]\n",
      " [0.29622211 0.42798491 0.43790227]\n",
      " [0.61775885 0.2369433  0.32536477]\n",
      " [0.70282702 0.20026797 0.28828391]\n",
      " [0.34872253 0.38048755 0.42211493]\n",
      " [0.3207606  0.48458052 0.37079805]\n",
      " [0.28416238 0.50851822 0.3736202 ]\n",
      " [0.20372131 0.50294001 0.47701217]\n",
      " [0.41581444 0.31267921 0.43805332]\n",
      " [0.3652326  0.34212281 0.44611715]\n",
      " [0.26692131 0.47970266 0.4238238 ]\n",
      " [0.38998916 0.35537837 0.39979226]\n",
      " [0.06516583 0.93264583 0.17335461]\n",
      " [0.15873333 0.6102058  0.43908987]\n",
      " [0.4224488  0.32375895 0.4211707 ]\n",
      " [0.348114   0.35763331 0.4605486 ]\n",
      " [0.60001454 0.26768325 0.30401903]\n",
      " [0.18773725 0.49638896 0.52051517]\n",
      " [0.196215   0.63056345 0.3446904 ]\n",
      " [0.21361097 0.49311899 0.47996889]\n",
      " [0.34759993 0.30222634 0.52530881]\n",
      " [0.15719448 0.76264401 0.26880523]\n",
      " [0.43013232 0.30207862 0.42607367]\n",
      " [0.53615518 0.29749885 0.32888527]\n",
      " [0.38366561 0.26658357 0.52601309]\n",
      " [0.77831138 0.21962941 0.18909258]\n",
      " [0.47565061 0.30208098 0.37258052]\n",
      " [0.06413678 0.87934451 0.30330371]\n",
      " [0.24916954 0.45948073 0.45910597]\n",
      " [0.40696537 0.37018111 0.36966425]\n",
      " [0.27032539 0.66773391 0.2292823 ]\n",
      " [0.41772115 0.28844778 0.46777289]\n",
      " [0.18114832 0.55124041 0.45524119]\n",
      " [0.38868509 0.28081925 0.51410356]\n",
      " [0.45786284 0.31088429 0.38008263]\n",
      " [0.46783297 0.31816428 0.37952347]\n",
      " [0.27360305 0.41705194 0.47157811]\n",
      " [0.18636606 0.22789154 0.75254191]\n",
      " [0.59357409 0.23641759 0.35022788]\n",
      " [0.15174214 0.67565458 0.38840664]\n",
      " [0.25371179 0.50893569 0.40618772]\n",
      " [0.70877229 0.22322849 0.25418377]\n",
      " [0.7121612  0.19200746 0.28974526]\n",
      " [0.54954659 0.25870407 0.36680222]\n",
      " [0.5942173  0.23706266 0.35156467]\n",
      " [0.3332425  0.36719832 0.46534768]\n",
      " [0.1859523  0.62023007 0.40517733]\n",
      " [0.64229267 0.2274816  0.31249728]\n",
      " [0.65438756 0.24249512 0.28209132]\n",
      " [0.217944   0.52663835 0.41953614]\n",
      " [0.28504831 0.43870976 0.45560188]\n",
      " [0.35948559 0.25585519 0.5655529 ]\n",
      " [0.60784013 0.20513329 0.38162408]\n",
      " [0.37970058 0.28782161 0.50554813]\n",
      " [0.16080382 0.73733314 0.3034143 ]\n",
      " [0.34010078 0.45334342 0.36832376]\n",
      " [0.45207506 0.36679327 0.32721937]\n",
      " [0.89375339 0.16091126 0.11686017]\n",
      " [0.14856674 0.68019299 0.3646573 ]\n",
      " [0.65935345 0.22649819 0.29931825]\n",
      " [0.20716217 0.695799   0.27033944]\n",
      " [0.72497833 0.20434748 0.25809905]\n",
      " [0.26382148 0.38526859 0.50652393]\n",
      " [0.75033368 0.19485693 0.24542513]\n",
      " [0.19101238 0.61723165 0.37009804]\n",
      " [0.27806159 0.31072366 0.59202892]\n",
      " [0.32648471 0.2562724  0.55986575]\n",
      " [0.39053763 0.31491573 0.45714704]\n",
      " [0.26856606 0.40198476 0.49577619]\n",
      " [0.15357916 0.69497071 0.34309412]\n",
      " [0.50432312 0.36743395 0.26860164]\n",
      " [0.20294012 0.53415528 0.44587522]\n",
      " [0.28071326 0.36968325 0.5212178 ]\n",
      " [0.68021376 0.20082288 0.3096642 ]\n",
      " [0.23768347 0.42389214 0.50925865]\n",
      " [0.20671673 0.50406826 0.44433557]\n",
      " [0.49486014 0.28486998 0.38466383]\n",
      " [0.39668378 0.36434311 0.40090941]\n",
      " [0.17019226 0.70143243 0.3207464 ]\n",
      " [0.64911392 0.22091577 0.31638049]\n",
      " [0.42520287 0.33143258 0.39896166]\n",
      " [0.44136617 0.33445765 0.39124036]\n",
      " [0.23213748 0.45070173 0.50120121]\n",
      " [0.59501948 0.25895965 0.31835335]\n",
      " [0.59300035 0.25720213 0.33048025]\n",
      " [0.24116239 0.47992481 0.44957231]\n",
      " [0.33063034 0.40044426 0.41856361]\n",
      " [0.21017786 0.62281322 0.34960749]\n",
      " [0.59636781 0.23365473 0.35023251]\n",
      " [0.26999472 0.60886238 0.2904155 ]\n",
      " [0.2131099  0.4577882  0.51554982]\n",
      " [0.29656508 0.53701907 0.32836645]\n",
      " [0.34639946 0.34061905 0.48414176]\n",
      " [0.27568583 0.42391637 0.46910836]\n",
      " [0.25046506 0.67551581 0.25188519]\n",
      " [0.87380772 0.17043418 0.13173239]\n",
      " [0.75735502 0.19053107 0.24199092]\n",
      " [0.17752845 0.59638802 0.42540561]\n",
      " [0.50191851 0.28922702 0.37994367]\n",
      " [0.27452805 0.4357345  0.45233183]\n",
      " [0.21477832 0.60499489 0.35566946]\n",
      " [0.13247736 0.69829327 0.35020192]\n",
      " [0.79227832 0.17948131 0.2182139 ]\n",
      " [0.19502837 0.47825197 0.51362482]\n",
      " [0.68544724 0.23994389 0.25428731]\n",
      " [0.22621185 0.48513104 0.4900271 ]\n",
      " [0.32012892 0.45515057 0.37782551]\n",
      " [0.44480415 0.28664485 0.43727423]\n",
      " [0.26537464 0.42271846 0.47532766]\n",
      " [0.31848811 0.34868402 0.5154193 ]\n",
      " [0.2622483  0.42774828 0.47647529]\n",
      " [0.3486228  0.40455389 0.41152436]\n",
      " [0.72065059 0.19691473 0.27445856]\n",
      " [0.25655958 0.47684967 0.44137733]\n",
      " [0.42386974 0.32353322 0.41895164]\n",
      " [0.46817134 0.30923961 0.38643838]\n",
      " [0.33224333 0.50659909 0.31052713]\n",
      " [0.28301398 0.50731574 0.38815782]\n",
      " [0.46600991 0.32536168 0.37392271]\n",
      " [0.47582748 0.35733623 0.32076664]\n",
      " [0.54995924 0.23849589 0.38789121]\n",
      " [0.20548722 0.59173142 0.38226522]\n",
      " [0.24724395 0.45718665 0.46832757]\n",
      " [0.33623922 0.4514605  0.36737525]\n",
      " [0.2895534  0.39260136 0.48211718]\n",
      " [0.31500168 0.36531676 0.48577863]\n",
      " [0.76035629 0.06132226 0.53932256]\n",
      " [0.38102618 0.44171743 0.31443162]\n",
      " [0.30575494 0.36802589 0.49733717]\n",
      " [0.41849962 0.29830985 0.45889886]\n",
      " [0.17247668 0.64574136 0.37642189]\n",
      " [0.46190506 0.21712167 0.51468248]\n",
      " [0.7271368  0.18594698 0.28395124]\n",
      " [0.32730163 0.28610975 0.56346569]\n",
      " [0.61604773 0.24916293 0.31228314]\n",
      " [0.22032071 0.66678077 0.29668095]\n",
      " [0.70694049 0.23357318 0.24293446]\n",
      " [0.14063981 0.73151533 0.32220822]\n",
      " [0.59266139 0.27036574 0.30753673]\n",
      " [0.43167601 0.34371487 0.37403888]\n",
      " [0.43928309 0.32596415 0.39862664]\n",
      " [0.74166955 0.21634443 0.23060487]\n",
      " [0.49823108 0.28892227 0.38135635]\n",
      " [0.2650374  0.65738552 0.25461406]\n",
      " [0.11238748 0.81380926 0.2862143 ]\n",
      " [0.21106563 0.49418004 0.45727454]\n",
      " [0.23382737 0.65054845 0.28583069]\n",
      " [0.79819862 0.19202561 0.19162232]\n",
      " [0.16402782 0.73547663 0.29492939]\n",
      " [0.41563561 0.33095463 0.41525381]\n",
      " [0.24262127 0.61541197 0.31647047]\n",
      " [0.39523564 0.35607714 0.4023192 ]\n",
      " [0.46849825 0.29608882 0.39601665]]\n",
      "Accuracy of:  0.6208133971291866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1-8', '9-10', '9-10', '9-10', '1-8', '11-30', '11-30', '1-8',\n",
       "       '9-10', '11-30', '1-8', '1-8', '11-30', '1-8', '9-10', '1-8',\n",
       "       '1-8', '11-30', '9-10', '1-8', '1-8', '11-30', '1-8', '9-10',\n",
       "       '9-10', '9-10', '1-8', '11-30', '1-8', '1-8', '1-8', '9-10',\n",
       "       '9-10', '9-10', '11-30', '1-8', '1-8', '1-8', '1-8', '1-8', '1-8',\n",
       "       '11-30', '11-30', '11-30', '9-10', '11-30', '1-8', '1-8', '9-10',\n",
       "       '9-10', '11-30', '11-30', '9-10', '1-8', '11-30', '9-10', '1-8',\n",
       "       '9-10', '11-30', '11-30', '1-8', '1-8', '1-8', '1-8', '1-8', '1-8',\n",
       "       '1-8', '1-8', '9-10', '9-10', '11-30', '9-10', '1-8', '1-8', '1-8',\n",
       "       '1-8', '1-8', '11-30', '11-30', '11-30', '9-10', '9-10', '11-30',\n",
       "       '11-30', '9-10', '1-8', '1-8', '9-10', '9-10', '1-8', '1-8', '1-8',\n",
       "       '1-8', '1-8', '9-10', '11-30', '9-10', '1-8', '11-30', '11-30',\n",
       "       '9-10', '9-10', '11-30', '9-10', '1-8', '9-10', '9-10', '9-10',\n",
       "       '1-8', '9-10', '1-8', '1-8', '9-10', '1-8', '1-8', '1-8', '1-8',\n",
       "       '11-30', '11-30', '9-10', '11-30', '11-30', '1-8', '1-8', '1-8',\n",
       "       '1-8', '1-8', '1-8', '1-8', '11-30', '11-30', '11-30', '11-30',\n",
       "       '1-8', '11-30', '9-10', '1-8', '1-8', '1-8', '1-8', '9-10', '9-10',\n",
       "       '9-10', '11-30', '9-10', '11-30', '9-10', '1-8', '1-8', '1-8',\n",
       "       '11-30', '9-10', '9-10', '9-10', '1-8', '1-8', '11-30', '1-8',\n",
       "       '9-10', '11-30', '9-10', '9-10', '9-10', '1-8', '1-8', '11-30',\n",
       "       '9-10', '1-8', '1-8', '11-30', '9-10', '1-8', '1-8', '9-10',\n",
       "       '9-10', '9-10', '1-8', '9-10', '1-8', '9-10', '1-8', '11-30',\n",
       "       '1-8', '11-30', '11-30', '11-30', '11-30', '11-30', '11-30',\n",
       "       '11-30', '11-30', '1-8', '9-10', '9-10', '9-10', '1-8', '11-30',\n",
       "       '9-10', '9-10', '11-30', '11-30', '1-8', '9-10', '9-10', '11-30',\n",
       "       '11-30', '11-30', '11-30', '9-10', '9-10', '11-30', '11-30',\n",
       "       '9-10', '9-10', '11-30', '9-10', '1-8', '1-8', '11-30', '1-8',\n",
       "       '9-10', '11-30', '9-10', '9-10', '11-30', '9-10', '9-10', '9-10',\n",
       "       '11-30', '1-8', '1-8', '1-8', '1-8', '11-30', '1-8', '1-8',\n",
       "       '11-30', '1-8', '1-8', '11-30', '11-30', '11-30', '9-10', '11-30',\n",
       "       '1-8', '9-10', '9-10', '1-8', '1-8', '11-30', '1-8', '1-8', '9-10',\n",
       "       '1-8', '9-10', '11-30', '11-30', '1-8', '11-30', '11-30', '9-10',\n",
       "       '1-8', '1-8', '11-30', '11-30', '1-8', '1-8', '1-8', '11-30',\n",
       "       '11-30', '11-30', '1-8', '1-8', '11-30', '11-30', '11-30', '11-30',\n",
       "       '9-10', '9-10', '11-30', '11-30', '9-10', '11-30', '1-8', '11-30',\n",
       "       '11-30', '9-10', '1-8', '11-30', '11-30', '9-10', '1-8', '9-10',\n",
       "       '1-8', '1-8', '1-8', '11-30', '1-8', '9-10', '9-10', '1-8', '9-10',\n",
       "       '1-8', '1-8', '1-8', '1-8', '9-10', '11-30', '1-8', '9-10',\n",
       "       '11-30', '1-8', '11-30', '11-30', '11-30', '9-10', '9-10', '9-10',\n",
       "       '1-8', '1-8', '11-30', '11-30', '11-30', '1-8', '9-10', '11-30',\n",
       "       '1-8', '9-10', '11-30', '11-30', '9-10', '9-10', '11-30', '1-8',\n",
       "       '1-8', '11-30', '9-10', '1-8', '11-30', '11-30', '9-10', '9-10',\n",
       "       '1-8', '1-8', '9-10', '1-8', '11-30', '9-10', '1-8', '9-10',\n",
       "       '9-10', '9-10', '1-8', '9-10', '9-10', '9-10', '1-8', '11-30',\n",
       "       '1-8', '9-10', '1-8', '1-8', '1-8', '9-10', '1-8', '1-8', '1-8',\n",
       "       '11-30', '1-8', '1-8', '1-8', '11-30', '1-8', '11-30', '1-8',\n",
       "       '11-30', '1-8', '1-8', '11-30', '11-30', '11-30', '11-30', '9-10',\n",
       "       '11-30', '1-8', '1-8', '9-10', '1-8', '1-8', '11-30', '1-8', '1-8',\n",
       "       '11-30', '11-30', '1-8', '11-30', '9-10', '9-10', '1-8', '9-10',\n",
       "       '11-30', '9-10', '11-30', '9-10', '1-8', '1-8', '9-10', '9-10',\n",
       "       '11-30', '9-10', '11-30', '1-8', '1-8', '11-30', '9-10', '11-30',\n",
       "       '9-10', '1-8', '9-10', '11-30', '11-30', '11-30', '11-30', '11-30',\n",
       "       '9-10', '1-8', '1-8', '9-10', '11-30', '11-30', '11-30', '1-8',\n",
       "       '9-10', '1-8', '1-8', '11-30', '1-8', '11-30', '9-10', '1-8',\n",
       "       '9-10', '1-8', '1-8', '1-8', '9-10', '9-10', '9-10', '9-10', '1-8',\n",
       "       '11-30', '9-10', '11-30', '11-30', '1-8', '11-30', '1-8', '1-8',\n",
       "       '11-30', '11-30', '9-10', '9-10', '1-8', '11-30', '11-30', '1-8',\n",
       "       '9-10', '1-8', '9-10', '9-10', '9-10', '11-30', '1-8', '9-10',\n",
       "       '11-30', '1-8', '11-30', '9-10', '11-30', '9-10', '9-10', '11-30',\n",
       "       '1-8', '11-30', '9-10', '9-10', '1-8', '9-10', '1-8', '11-30',\n",
       "       '11-30', '1-8', '9-10', '11-30', '1-8', '11-30', '11-30', '1-8',\n",
       "       '1-8', '1-8', '9-10', '9-10', '11-30', '1-8', '11-30', '1-8',\n",
       "       '11-30', '11-30', '1-8', '11-30', '9-10', '1-8', '11-30', '1-8',\n",
       "       '1-8', '9-10', '1-8', '11-30', '11-30', '11-30', '9-10', '11-30',\n",
       "       '11-30', '1-8', '11-30', '9-10', '1-8', '11-30', '9-10', '9-10',\n",
       "       '11-30', '9-10', '1-8', '1-8', '9-10', '9-10', '9-10', '1-8',\n",
       "       '1-8', '9-10', '11-30', '1-8', '11-30', '9-10', '1-8', '1-8',\n",
       "       '9-10', '1-8', '11-30', '9-10', '11-30', '11-30', '9-10', '9-10',\n",
       "       '9-10', '11-30', '1-8', '1-8', '11-30', '1-8', '11-30', '11-30',\n",
       "       '11-30', '11-30', '11-30', '11-30', '9-10', '9-10', '11-30',\n",
       "       '9-10', '9-10', '1-8', '9-10', '11-30', '9-10', '11-30', '11-30',\n",
       "       '9-10', '1-8', '11-30', '9-10', '1-8', '11-30', '1-8', '9-10',\n",
       "       '11-30', '9-10', '9-10', '1-8', '1-8', '1-8', '1-8', '9-10',\n",
       "       '9-10', '9-10', '11-30', '1-8', '1-8', '11-30', '1-8', '11-30',\n",
       "       '9-10', '11-30', '9-10', '9-10', '1-8', '1-8', '9-10', '9-10',\n",
       "       '11-30', '9-10', '1-8', '11-30', '9-10', '11-30', '11-30', '11-30',\n",
       "       '1-8', '1-8', '1-8', '9-10', '9-10', '9-10', '11-30', '1-8', '1-8',\n",
       "       '11-30', '1-8', '11-30', '11-30', '9-10', '11-30', '9-10', '1-8',\n",
       "       '11-30', '1-8', '11-30', '1-8', '11-30', '1-8', '9-10', '11-30',\n",
       "       '1-8', '11-30', '11-30', '1-8', '1-8', '9-10', '1-8', '9-10',\n",
       "       '11-30', '1-8', '11-30', '1-8', '1-8', '11-30', '11-30', '1-8',\n",
       "       '11-30', '11-30', '11-30', '11-30', '1-8', '11-30', '1-8', '11-30',\n",
       "       '11-30', '11-30', '1-8', '1-8', '9-10', '9-10', '11-30', '9-10',\n",
       "       '9-10', '1-8', '9-10', '9-10', '1-8', '11-30', '1-8', '1-8', '1-8',\n",
       "       '11-30', '1-8', '9-10', '1-8', '1-8', '9-10', '11-30', '11-30',\n",
       "       '11-30', '9-10', '9-10', '11-30', '9-10', '11-30', '11-30', '1-8',\n",
       "       '9-10', '1-8', '9-10', '11-30', '11-30', '9-10', '11-30', '1-8',\n",
       "       '1-8', '9-10', '1-8', '1-8', '11-30', '11-30', '1-8', '11-30',\n",
       "       '9-10', '11-30', '9-10', '1-8', '1-8', '9-10', '9-10', '1-8',\n",
       "       '11-30', '11-30', '1-8', '1-8', '1-8', '1-8', '9-10', '11-30',\n",
       "       '1-8', '1-8', '11-30', '9-10', '9-10', '1-8', '9-10', '11-30',\n",
       "       '11-30', '1-8', '1-8', '11-30', '1-8', '11-30', '1-8', '9-10',\n",
       "       '1-8', '11-30', '9-10', '9-10', '9-10', '9-10', '11-30', '1-8',\n",
       "       '11-30', '9-10', '1-8', '9-10', '11-30', '1-8', '9-10', '11-30',\n",
       "       '1-8', '1-8', '1-8', '9-10', '1-8', '1-8', '11-30', '9-10',\n",
       "       '11-30', '1-8', '11-30', '9-10', '11-30', '9-10', '9-10', '11-30',\n",
       "       '1-8', '1-8', '11-30', '1-8', '9-10', '11-30', '11-30', '1-8',\n",
       "       '9-10', '1-8', '9-10', '11-30', '1-8', '9-10', '9-10', '9-10',\n",
       "       '9-10', '1-8', '11-30', '1-8', '1-8', '11-30', '11-30', '1-8',\n",
       "       '1-8', '1-8', '11-30', '9-10', '11-30', '9-10', '9-10', '1-8',\n",
       "       '11-30', '9-10', '9-10', '11-30', '9-10', '1-8', '9-10', '1-8',\n",
       "       '11-30', '1-8', '11-30', '1-8', '1-8', '1-8', '1-8', '1-8',\n",
       "       '11-30', '11-30', '11-30', '11-30', '1-8', '11-30', '1-8', '11-30',\n",
       "       '9-10', '1-8'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76f0f6ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.6232057416267942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "# from sklearn.datasets import load_iris\n",
    "# ds = load_iris()\n",
    "# X = ds.data\n",
    "# y = ds.target\n",
    "lr_sk = SKLogisticRegression(solver='liblinear', max_iter=5000) # all params default\n",
    "\n",
    "lr_sk.fit(X_train,y_train)\n",
    "yhat = lr_sk.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e258cca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole-Weight</th>\n",
       "      <th>Shucked-Weight</th>\n",
       "      <th>Viscera-Weight</th>\n",
       "      <th>Shell-Weight</th>\n",
       "      <th>Female</th>\n",
       "      <th>Infant</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.084071</td>\n",
       "      <td>0.181335</td>\n",
       "      <td>0.150303</td>\n",
       "      <td>0.132324</td>\n",
       "      <td>0.147982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.066241</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.068261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614865</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.239065</td>\n",
       "      <td>0.171822</td>\n",
       "      <td>0.185648</td>\n",
       "      <td>0.207773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493243</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.182044</td>\n",
       "      <td>0.144250</td>\n",
       "      <td>0.149440</td>\n",
       "      <td>0.152965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.071897</td>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.051350</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>0.146018</td>\n",
       "      <td>0.313441</td>\n",
       "      <td>0.248151</td>\n",
       "      <td>0.314022</td>\n",
       "      <td>0.246637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.341420</td>\n",
       "      <td>0.294553</td>\n",
       "      <td>0.281764</td>\n",
       "      <td>0.258097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.181416</td>\n",
       "      <td>0.415796</td>\n",
       "      <td>0.352724</td>\n",
       "      <td>0.377880</td>\n",
       "      <td>0.305431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.722689</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>0.386931</td>\n",
       "      <td>0.356422</td>\n",
       "      <td>0.342989</td>\n",
       "      <td>0.293473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.858108</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.172566</td>\n",
       "      <td>0.689393</td>\n",
       "      <td>0.635171</td>\n",
       "      <td>0.495063</td>\n",
       "      <td>0.491779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Length  Diameter    Height  Whole-Weight  Shucked-Weight  \\\n",
       "0     0.513514  0.521008  0.084071      0.181335        0.150303   \n",
       "1     0.371622  0.352941  0.079646      0.079157        0.066241   \n",
       "2     0.614865  0.613445  0.119469      0.239065        0.171822   \n",
       "3     0.493243  0.521008  0.110619      0.182044        0.144250   \n",
       "4     0.344595  0.336134  0.070796      0.071897        0.059516   \n",
       "...        ...       ...       ...           ...             ...   \n",
       "4172  0.662162  0.663866  0.146018      0.313441        0.248151   \n",
       "4173  0.695946  0.647059  0.119469      0.341420        0.294553   \n",
       "4174  0.709459  0.705882  0.181416      0.415796        0.352724   \n",
       "4175  0.743243  0.722689  0.132743      0.386931        0.356422   \n",
       "4176  0.858108  0.840336  0.172566      0.689393        0.635171   \n",
       "\n",
       "      Viscera-Weight  Shell-Weight  Female  Infant  Male  \n",
       "0           0.132324      0.147982       0       0     1  \n",
       "1           0.063199      0.068261       0       0     1  \n",
       "2           0.185648      0.207773       1       0     0  \n",
       "3           0.149440      0.152965       0       0     1  \n",
       "4           0.051350      0.053313       0       1     0  \n",
       "...              ...           ...     ...     ...   ...  \n",
       "4172        0.314022      0.246637       1       0     0  \n",
       "4173        0.281764      0.258097       0       0     1  \n",
       "4174        0.377880      0.305431       0       0     1  \n",
       "4175        0.342989      0.293473       1       0     0  \n",
       "4176        0.495063      0.491779       0       0     1  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "initData.drop('Ring-Range', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514e7dc",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2acd5f",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c5868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
